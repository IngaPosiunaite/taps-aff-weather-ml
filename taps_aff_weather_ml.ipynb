{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH6xeyU5Uxte"
      },
      "source": [
        "# \"Taps aff\"\n",
        "\"Taps aff\" is a Scottish expression that literally means \"tops off\". It refers to the act of removing one's shirt, typically by men, in warm weather. This phrase is commonly used in Scotland, particularly in Glasgow, to describe good weather or good times being had. The expression is often used humorously, as it's a phenomenon rarely seen in Glasgow due to its typically cool climate. When someone declares \"taps aff,\" it usually indicates that the weather is unusually warm or that a celebratory atmosphere is present.\n",
        "\n",
        "\n",
        "Objective\n",
        "*   Develop a deep learning system that predicts whether a day in Glasgow is a \"taps aff\" day based on weather data.\n",
        "*   Glasgow weather dataset: https://drive.google.com/file/d/16O9Zoo8npYXQqniAB7K2K40Tlkr3ozSQ/view?usp=sharing Credit: https://open-meteo.com/\n",
        "*   Taps aff dataset: https://drive.google.com/file/d/1XVNe0XmS-_-umhNwQUVMi3xE04nGKx1R/view?usp=sharing\n",
        "\n",
        "\n",
        "Top Tips\n",
        "\n",
        "1.   Implement a regression deep learning model to estimate missing Glasgow weather parameters. Train the regression model on complete data points, then use the trained model to fill in missing values.\n",
        "2.   Feature engineer the date into day and month to help predict these missing values.\n",
        "3.   Merge the two datasets by changing dates in the taps aff dataset into the same format as the weather dataset.\n",
        "4.   Implement a binary classification (use softmax and sparse_categorical_crossentropy) deep learning model to predict the taps aff days from 2023 to 2025.\n",
        "5.   Use test sets on both the regression and classification to evaluate their performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGcyp3xjLHbt"
      },
      "source": [
        "## Load and explore Glasgow weather data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH8-_TVAs2QW"
      },
      "outputs": [],
      "source": [
        "# Read in glasgow weather and explore\n",
        "import pandas as pd\n",
        "df_weather = pd.read_csv('/content/sample_data/glasgow_weather.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wvsy8U-W1HW7"
      },
      "outputs": [],
      "source": [
        "df_weather.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bej1at_l0upJ"
      },
      "outputs": [],
      "source": [
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r_S5FOMU_NF"
      },
      "outputs": [],
      "source": [
        "df_weather.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGOZzwY913EK"
      },
      "outputs": [],
      "source": [
        "# Look at missing daylight_duration\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df_weather['daylight_duration'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5mfJe5OR5io"
      },
      "outputs": [],
      "source": [
        "# Create two new features to help make a model to replace missing daylight_duration\n",
        "# Feature engineering: extract *day* and *month* from the date string\n",
        "# Why: daylight duration is strongly seasonal, so month/day help the regression model learn that pattern\n",
        "df_weather['day'] = df_weather['date'].apply(lambda x: int(x[8:]))\n",
        "df_weather['month'] = df_weather['date'].apply(lambda x: int(x[5:7]))\n",
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsuB2Oc442gh"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into:\n",
        "# 1) rows WITH missing daylight_duration (used later for prediction)\n",
        "# 2) rows with KNOWN daylight_duration (used to train the regression model)\n",
        "\n",
        "# Create to new dataframes - one with missing 730 days of daylight and one without after initial 730 days\n",
        "df_weather_with_nan = df_weather.iloc[:730]\n",
        "df_weather_without_nan = df_weather.iloc[730:]\n",
        "\n",
        "# Alternatively and more elegantly\n",
        "df_weather_with_nan = df_weather[df_weather['daylight_duration'].isna()]\n",
        "df_weather_without_nan = df_weather[df_weather['daylight_duration'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jWg5rmPRowO"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_weather_with_nan.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FRHkMkTYvbO"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_weather_without_nan.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwj6nIFiqj3_"
      },
      "outputs": [],
      "source": [
        "# Create training arrays for regression\n",
        "# X = input features (all columns except the target and raw date string)\n",
        "# y = target value to predict (daylight_duration)\n",
        "x = df_weather_without_nan.drop(['daylight_duration','date'], axis=1).to_numpy()\n",
        "y = df_weather_without_nan[['daylight_duration']].to_numpy()\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG13mv55ZK3O"
      },
      "outputs": [],
      "source": [
        "# Training and testing sets\n",
        "boundary = int(x.shape[0] * 0.8)\n",
        "x_train = x[:boundary]\n",
        "y_train = y[:boundary]\n",
        "x_test = x[boundary:]\n",
        "y_test = y[boundary:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvtxphcztC32"
      },
      "outputs": [],
      "source": [
        "# Standardise inputs using TRAINING statistics only (prevents data leakage)\n",
        "# Standardisation helps neural networks train more smoothly when features are on similar scales\n",
        "means = x_train.mean(axis=0)\n",
        "stds = x_train.std(axis=0)\n",
        "x_train = (x_train - means) / stds\n",
        "\n",
        "# And test set with values from training set\n",
        "x_test = (x_test - means) / stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsFAWWyHLHcB"
      },
      "source": [
        "## Regression model to impute missing `daylight_duration`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTUb3n56rggu"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Regression model (deep network with residual blocks)\n",
        "# Goal: learn a mapping from weather/date features -> daylight_duration\n",
        "# Residual connections help deeper networks train by providing a \"shortcut\" path for gradients\n",
        "\n",
        "# Input block\n",
        "inputs = keras.layers.Input(shape=(6,))\n",
        "z = inputs\n",
        "\n",
        "# Projection layer\n",
        "z = keras.layers.Dense(128)(z)\n",
        "\n",
        "# Two blocks\n",
        "for i in range(2):\n",
        "  # Residual connection (ensemble like)\n",
        "  res = z\n",
        "\n",
        "  # Layer norm\n",
        "  z = keras.layers.LayerNormalization()(z)\n",
        "\n",
        "  # Inverted bottleneck (dimension reduction)\n",
        "  z = keras.layers.Dense(4*128)(z)\n",
        "  z = keras.activations.gelu(z) # probabilistic interpretation of dropout (ie ensemble like)\n",
        "  z = keras.layers.Dense(128)(z)\n",
        "\n",
        "  # Residual connection\n",
        "  z = keras.layers.Add()([res,z])\n",
        "\n",
        "# Layer norm\n",
        "z = keras.layers.LayerNormalization()(z)\n",
        "\n",
        "# Regression output block\n",
        "z = keras.layers.Dense(1)(z)\n",
        "outputs = keras.activations.gelu(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WN3U2RtZ7KE"
      },
      "outputs": [],
      "source": [
        "# Prepare model\n",
        "model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()\n",
        "model.compile(\n",
        "  loss=keras.losses.MeanSquaredError(),\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.01, decay_steps=30*165)) # cosine annealing to help converge\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eoncx12Z-Cc"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrDWXOxTb2Q4"
      },
      "outputs": [],
      "source": [
        "# Performance on test set\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaGr9MNtUPqD"
      },
      "outputs": [],
      "source": [
        "# Prepare for inference and replacing missing values\n",
        "x = df_weather_with_nan.drop(['daylight_duration','date'], axis=1).to_numpy()\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzWUjEqRUPqE"
      },
      "outputs": [],
      "source": [
        "# Standardise the input with above values\n",
        "x = (x - means) / stds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sA0c-zQX2rf1"
      },
      "outputs": [],
      "source": [
        "# Infer\n",
        "y_pred = model.predict(x)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCNf31mBU3OZ"
      },
      "outputs": [],
      "source": [
        "# Column 2 is where missing values are\n",
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qsNhJNw2-Gl"
      },
      "outputs": [],
      "source": [
        "# Replace the column 2 values (first 730) with the model predictions\n",
        "# df_weather.iloc[:730, 2] = y_pred\n",
        "\n",
        "# Alternatively and more elegantly\n",
        "df_weather.loc[df_weather['daylight_duration'].isna(), 'daylight_duration'] = y_pred\n",
        "\n",
        "\n",
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmy35bueRC_s"
      },
      "source": [
        "## Read and explore Glasgow weather data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMiyFL5vZ5B3"
      },
      "outputs": [],
      "source": [
        "df_taps_aff = pd.read_csv('/content/sample_data/taps_aff.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9nqfNcBanDj"
      },
      "outputs": [],
      "source": [
        "df_taps_aff.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVn3-24Lapnq"
      },
      "outputs": [],
      "source": [
        "df_taps_aff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPM7HoJXaq4I"
      },
      "outputs": [],
      "source": [
        "df_taps_aff.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3-2ztJLayH-"
      },
      "outputs": [],
      "source": [
        "# Change date format into same as weather dataset\n",
        "df_taps_aff['date'] = df_taps_aff['date'].apply(lambda x: x[6:] + \"-\" + x[3:5] + \"-\" + x[:2])\n",
        "df_taps_aff.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWKPJFdshs60"
      },
      "outputs": [],
      "source": [
        "df_taps_aff.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lua5jnFvLHcI"
      },
      "source": [
        "## Join two dataframes together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo29TezafuzE"
      },
      "outputs": [],
      "source": [
        "df_joined = df_weather.merge(df_taps_aff, on='date', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32M6YkCmf0BE"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_joined.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6dXzLQ6giYU"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_joined.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZaR6f1rhomr"
      },
      "outputs": [],
      "source": [
        "# Create two new dataframes - one with missing 730 days of taps aff and one without before the final 730 days\n",
        "df_joined_with_nan = df_joined.iloc[-730:]\n",
        "df_joined_without_nan = df_joined.iloc[:-730]\n",
        "\n",
        "# Alternatively and more elegantly\n",
        "df_joined_with_nan = df_joined[df_joined['tap_aff'].isna()]\n",
        "df_joined_without_nan = df_joined[df_joined['tap_aff'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOjP0-M7homs"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_joined_without_nan.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLO2Uf8whoms"
      },
      "outputs": [],
      "source": [
        "# Check that worked\n",
        "df_joined_with_nan.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AuKOodwhoms"
      },
      "outputs": [],
      "source": [
        "# Build classification arrays\n",
        "# X = input features (weather + engineered date features)\n",
        "# y = binary label (tap_aff). Convert boolean to int (0/1) for training\n",
        "x = df_joined_without_nan.drop(['tap_aff','date'], axis=1).to_numpy()\n",
        "y = df_joined_without_nan[['tap_aff']].to_numpy(dtype='int8') # convert from bool to int\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtJo4AEjhoms"
      },
      "outputs": [],
      "source": [
        "# Training and testing sets\n",
        "boundary = int(x.shape[0] * 0.8)\n",
        "x_train = x[:boundary]\n",
        "y_train = y[:boundary]\n",
        "x_test = x[boundary:]\n",
        "y_test = y[boundary:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "087iNXsChomt"
      },
      "outputs": [],
      "source": [
        "# Standardise training set\n",
        "means = x_train.mean(axis=0)\n",
        "stds = x_train.std(axis=0)\n",
        "x_train = (x_train - means) / stds\n",
        "\n",
        "# And test set with values from training set\n",
        "x_test = (x_test - means) / stds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiDNtN3aLHcu"
      },
      "source": [
        "## Binary classification model: predict “taps aff” days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NyGnT-xmM10"
      },
      "outputs": [],
      "source": [
        "# Binary classification model (deep network with residual blocks)\n",
        "# Goal: predict tap_aff (0/1) from weather features\n",
        "\n",
        "# Input block\n",
        "inputs = keras.layers.Input(shape=(7,))\n",
        "z = inputs\n",
        "\n",
        "# Projection layer\n",
        "z = keras.layers.Dense(128)(z)\n",
        "\n",
        "# Two blocks\n",
        "for i in range(2):\n",
        "  # Residual connection (ensemble like)\n",
        "  res = z\n",
        "\n",
        "  # Layer norm\n",
        "  z = keras.layers.LayerNormalization()(z)\n",
        "\n",
        "  # Inverted bottleneck (dimension reduction)\n",
        "  z = keras.layers.Dense(4*128)(z)\n",
        "  z = keras.activations.gelu(z) # probabilistic interpretation of dropout (ie ensemble like)\n",
        "  z = keras.layers.Dense(128)(z)\n",
        "\n",
        "  # Residual connection\n",
        "  z = keras.layers.Add()([res,z])\n",
        "\n",
        "# Layer norm\n",
        "z = keras.layers.LayerNormalization()(z)\n",
        "\n",
        "# Sigmoid output block\n",
        "z = keras.layers.Dense(1)(z)\n",
        "outputs = keras.activations.sigmoid(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb6gdu7nfmRN"
      },
      "outputs": [],
      "source": [
        "# Prepare model\n",
        "model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.summary()\n",
        "model.compile(\n",
        "  loss=keras.losses.BinaryCrossentropy(),\n",
        "  optimizer=keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.01, decay_steps=30*165)) # cosine annealing to help converge\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBAa_92JfmRN"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_7xCkBPfmRN"
      },
      "outputs": [],
      "source": [
        "# Performance on test set\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-SC4ggjgkU"
      },
      "outputs": [],
      "source": [
        "# Prepare for inference and replacing missing values\n",
        "x = df_joined_with_nan.drop(['tap_aff','date'], axis=1).to_numpy()\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLwaJJSHjgkV"
      },
      "outputs": [],
      "source": [
        "# Standardise the input with above values\n",
        "x = (x - means) / stds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIbifZkSjgkV"
      },
      "outputs": [],
      "source": [
        "# Infer\n",
        "y_pred = model.predict(x)\n",
        "\n",
        "import numpy as np\n",
        "print(np.round(y_pred)) # np.round to convert simoid predictions to 0/1 false/true values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "103b6042"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this project, I built a deep learning system to predict whether a day in Glasgow is a “taps aff” day based on weather data.\n",
        "I used a regression model to estimate missing weather values and then trained a binary classification model to detect warm days.\n",
        "The model learned meaningful seasonal patterns, such as longer daylight in summer and shorter daylight in winter.\n",
        "This project strengthened my understanding of data preprocessing, feature engineering, missing value handling, and machine learning workflows.\n",
        "Future improvements could include adding more weather features, tuning hyperparameters, and testing alternative model architectures.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}